Man is to Computer Programmer as Woman is to homemaker?
Part 1
After reading the abstraction:
The main problem the paper is solving: Gender bias that word embedding has.
Main contribution of the paper: debias the embeddings and prevent amplifying gender bias in the real world.

After reading the introduction:
Bias :1. Location of vector 2. Gender stereotype 
The main problem is that word embeddings have gender bias hence introducing bias to the real-world. Gender bias in word embeddings are usually cause by either the location of the word vector or gender stereotype in the real world.
I am confused about how to define the vector. What stands for their direction? What stands for their length? The question is one of the basis of word embeddings.

After reading the results section:
The author sets examples to show that their debias algorithms works. 
For Direct Bias, consider the analogy puzzle, he to doctor as she to X. After debias, X would be physician instead of nurse. For Indirect Bias, the relevance between receptionist and softball etc. are removed. What is more, the appropriate analogies are not removed or changed after the debias algorithm.
It is compelling because they demonstrate graphs to collect all the instances, comparing the gender bias in word embeddings before and after their debias algorithms. 
